{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module 5, Lab 1 - Correlation\n",
    "=============================\n",
    "\n",
    "This final series of labs explores everything you need to execute\n",
    "projects from start to finish based on a few different analyses.\n",
    "\n",
    "In this lab, we will explore how to assess relationships between\n",
    "variables using correlation in R.\n",
    "\n",
    "In this example, we have a dataset, inspired by a dataset published on\n",
    "kaggle (<https://www.kaggle.com/unsdsn/world-happiness>). In this\n",
    "dataset, several regions of the world are compared on dimensions such as\n",
    "their generosity, happiness, GDP, and so forth.\n",
    "\n",
    "Load Packages\n",
    "=============\n",
    "\n",
    "In this lab, we will use the `ggplot2` package for data visualization,\n",
    "the `corrplot` package for making visual correlation tables, and the\n",
    "`psych` package for detecting skew and making correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD PACKAGES ####\n",
    "install.packages('corrplot')\n",
    "install.packages('psych')\n",
    "library(ggplot2)\n",
    "library(corrplot)\n",
    "library(psych)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "=========\n",
    "\n",
    "Next, let's load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD DATA ####\n",
    "dat <- read.csv(\"datasets/regionalhappy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the dataset, we see the names are a little messy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rename them easily with `names()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(dat) <- c(\"Happiness\", \"GDP\", \"Family\", \"Life.Expect\", \"Freedom\", \"Generosity\", \"Trust.Gov\", \"Dystopia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first few rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better.\n",
    "\n",
    "Bivariate Correlation\n",
    "=====================\n",
    "\n",
    "Next, let's see how variables correlate. In our research study, we want\n",
    "to understand happiness. We can compute correlations between variables\n",
    "with `cor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(dat$Happiness, dat$Life.Expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the correlation is *r* = .57. A brief refresher: correlations\n",
    "range between zero (no association between variables) and 1.0 (a\n",
    "one-to-one association). They can also be positive (as one variable\n",
    "increases, so does the other) or negative (as one variable increases,\n",
    "the other decreases).\n",
    "\n",
    "So, in this case, we have a large, positive link between the happiness\n",
    "of a region and health / life expectancy in that region. The\n",
    "statistician Jacob Cohen suggested the following guidelines:\n",
    "\n",
    "\n",
    "\n",
    "|        | Correlation          | Meaning  |\n",
    "| ------------- |:-------------:|-----------:|\n",
    "| 1.  | 0 - 0.1 | Negligible |\n",
    "| 2.  | 0.1 - 0.3     |  Small |\n",
    "| 3. | 0.3 - 0.5      |  Medium |\n",
    "| 4. | 0.50 +      |  Large |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, then, that this association would count as \"large\" by Cohen's\n",
    "guidelines.\n",
    "\n",
    "We can also easily visualize this correlation with `ggplot2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data=dat, aes(x=Happiness, y=Life.Expect))+\n",
    "  geom_point()+\n",
    "  theme_light()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-8-1.png)\n",
    "\n",
    "### A Sample Estimate\n",
    "\n",
    "We have discussed statistical hypothesis testing a number of times in\n",
    "this course, but we haven't yet discussed it in detail with respect to\n",
    "correlations. So, here is a brief refresher on the need for significance\n",
    "testing, applied to correlation.\n",
    "\n",
    "Here, are working with a sample of regions at one point in time. What if\n",
    "we wanted to estimate, in a broader way, the association between\n",
    "happiness and life expectancy? Assuming our data are representative of\n",
    "the broader population (e.g., across times, regions, etc.; a big\n",
    "assumption!), we could use this sample correlation (symbol: *r* = .78)\n",
    "as an estimate of the population correlation (symbol: *ρ*). In other\n",
    "words, we don't know the true correlation between happiness and life\n",
    "expectancy in the population, but if we can trust this data to\n",
    "adequately represent it, we can *estimate* it at .78.\n",
    "\n",
    "The estimation piece is important. Often, people look at the sample\n",
    "correlation and don't realize that it's specific to that sample. For\n",
    "example, an organization might collect a survey to assess the link\n",
    "between customer satisfaction and consumption. Whatever correlation\n",
    "observed in the sample is only an estimate--our best guess--of the\n",
    "correlation in the broader population. Were that organization to collect\n",
    "another sample, they would get a different correlation. Every time, the\n",
    "correlation would vary slightly, because the sample is different and\n",
    "only representing (but not being) the population. This raises an\n",
    "important point: sample correlations are imperfect estimates of their\n",
    "population counterparts. The sample estimate has error built into it.\n",
    "\n",
    "One important consequence is that it is possible that the correlation in\n",
    "the population is actually zero (*H*<sub>0</sub> : *ρ* = 0) even when it\n",
    "is not in the sample (e.g., *r* = .12). In other words, the sample\n",
    "correlation could be a statistical fluke of the sample. We cannot say,\n",
    "just because the sample correlation is nonzero, that the two variables\n",
    "truly are correlated in the population. We will need to conduct a\n",
    "statistical significance test first.\n",
    "\n",
    "Further, we can *only* trust the sample correlation as an estimate of\n",
    "the population correlation *if* the data are representative. If only a\n",
    "certain kind of person selects into the survey (e.g., a certain\n",
    "personality type, people who have strong feelings about a product,\n",
    "etc.), then the sample correlation will estimate the correlation for\n",
    "*that population only.* This essentially means that all research data is\n",
    "biased toward whoever is over-represented in the sample. For this\n",
    "reason, getting good information on whoever is represented in one's data\n",
    "is very important for qualifying the results. In some cases, it may be\n",
    "worth it to gather data from multiple different sources or methods and\n",
    "cross-reference the results for very important decisions.\n",
    "\n",
    "Significance Test\n",
    "=================\n",
    "\n",
    "If we want to test the correlation for significance, we can simply\n",
    "replace `cor()` with `cor.test()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.test(dat$Happiness, dat$Life.Expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that a *t*-test was conducted.\n",
    "\n",
    "Recall that a *t*-test compares the size of the *observed correlation*\n",
    "(*r*) against the value in the null hypothesis (zero), divided by what\n",
    "is typically expected by chance:\n",
    "\n",
    "$$t=\\frac{result - null }{chance}$$\n",
    "\n",
    "The top of the faction is key here. The more the data \"disagree\" with\n",
    "the null, the larger the *t*-value and hence more evidence for a real\n",
    "association When all is said and done, a large *t*-value tells you that\n",
    "the association (top of fraction) is considerably larger than expected\n",
    "by chance (bottom of fraction). Here, our *t* value is 15.52, meaning\n",
    "that the correlation is 15.52 times larger than would typically be\n",
    "expected by chance. Thus, chance seems an unlikely explanation for the\n",
    "result.\n",
    "\n",
    "This is converted in to a *p*-value, which R tells us is very small. In\n",
    "other words, it would be exceedingly unlikely to get a result this big\n",
    "if the null were true. Because it is &lt; .05, we can say that this\n",
    "result would happen very rarely by chance. We reject the null hypothesis\n",
    "and conclude that this correlation is not due to chance.\n",
    "\n",
    "Using the same information, we can make a reasonable guess about what\n",
    "the correlation in the population is. We see that `cor.test()` has given\n",
    "us a 95% confidence interval of \\[0.71, 0.84\\], meaning that we are 95%\n",
    "confident that the population value (*ρ*) is in that range. By \"95%\n",
    "confident,\" we mean that this range includes the population value 95% of\n",
    "the time. If we act on it and trust it, we are right 95% of the time.\n",
    "\n",
    "So, we are pretty certain that, even though we have a sample (a small\n",
    "sample, too!), that there is a large correlation in the population\n",
    "between happiness and life satisfaction. Even after taking the\n",
    "uncertainty of our sample into account (e.g., with the *t*-test and 95%\n",
    "CI), we still feel confident that there is a larger link between these\n",
    "two variables.\n",
    "\n",
    "Caveat: Normality\n",
    "=================\n",
    "\n",
    "It should be noted that correlations work best with normally distributed\n",
    "(bell curve, symmetrical) data. We can briefly check the skew of the\n",
    "variables. I won't use `ggplot2` here since we aren't making figures\n",
    "we'd want to share:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(dat$Happiness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-10-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(dat$Life.Expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-10-2.png)\n",
    "\n",
    "We see here that both variables are decently normally distributed, but\n",
    "life expectancy is possibly negative skewed (i.e., \"skew left\"). We can\n",
    "get a metric of the skew using the `skew()` command in the `psych`\n",
    "package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psych::skew(dat$Life.Expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People disagree about what is acceptable skew, but usually a value less\n",
    "than +/- 1.0 raises no alarms. Here, we can safely go about our\n",
    "business.\n",
    "\n",
    "However, if we had a bigger skew problem, we could also address the skew\n",
    "by transforming the variable. (There are also backup options, such as\n",
    "Spearman's correlation, but we won't explore that in this class beyond\n",
    "what was covered in Module 3).\n",
    "\n",
    "Correlations are based on variance, so anything that biases a mean\n",
    "(e.g., skew) also interferes with the correlation. In general, skew\n",
    "reduces correlations. For a more robust test of the correlation, you can\n",
    "transform the data by performing a mathematical operation to every\n",
    "score. There are many such operations we can try. In general, taking the\n",
    "square root of every score reduces skew, but the catch is that the\n",
    "variable must be positively skewed and no scores may be negative. For\n",
    "the sake of illustration, let's try this.\n",
    "\n",
    "First, let's \"reverse\" the variable. Take the maximum score, add one to\n",
    "it, and subtract your score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat$Life.Expect2 <- max(dat$Life.Expect) + 1 - dat$Life.Expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reverses the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(dat$Life.Expect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-13-1.png)\n",
    "\n",
    "Now we can perform any number of operations. The square root is the most\n",
    "mild transformation. We can also take the natural log of every score (no\n",
    "values may be zero!). In general, these operations reduce big numbers\n",
    "more than small numbers and thus rein in the long tail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(sqrt(dat$Life.Expect2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-14-1.png)\n",
    "We could save this transformed version, then re-reverse it and use that\n",
    "in subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat$Life.Expect2 <- sqrt(dat$Life.Expect2)\n",
    "dat$Life.Expect2 <- max(dat$Life.Expect2) + 1 - dat$Life.Expect2\n",
    "\n",
    "cor.test(dat$Happiness, dat$Life.Expect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here the results barely changed. In this case, that wasn't really\n",
    "necessary because the variable was not that skewed to begin with. You\n",
    "will find, in many cases, that it is very helpful, however. In those\n",
    "cases, there are many online guides to data transformation.\n",
    "\n",
    "Of course, if you are predicting something that has a very non-normal\n",
    "distribution (e.g., categorical variables, counts of things often have\n",
    "many zeros, etc.) then correlation may not be the best tool to use. A\n",
    "more sophisticated data modeling technique may be warranted. However,\n",
    "\n",
    "Correlations Among Many Variables\n",
    "=================================\n",
    "\n",
    "Often we want to examine the correlations among many variables at once.\n",
    "In this case, we could look at a matrix of correlations. This can be\n",
    "done by inputting a data.frame of all the variables of interest into the\n",
    "`cor()` function:\n",
    "\n",
    "You can make your own data.frame of just the variables you want to\n",
    "analyze, or we could simply use `dat`. Here, I want happiness, life\n",
    "expectancy, GDP, and generosity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor(data.frame(dat$Happiness, dat$Life.Expect, dat$GDP, dat$Generosity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see that happiness, life expectancy, and GDP are all\n",
    "highly intercorrelated, whereas generosity is seemingly less related.\n",
    "Thus, we may conceive that we have a \"cluster\" of intercorrelated\n",
    "variables around happiness.\n",
    "\n",
    "If you wanted significance tests, you can request that with the\n",
    "`corr.test()` function in the `psych` package, which returns a grid of\n",
    "*p*-values. This will also give you other contents; we can request only\n",
    "the *p*-values by adding `$p` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.test(data.frame(dat$Happiness, dat$Life.Expect, dat$GDP, dat$Generosity))$p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only the correlations below the diagonal are correct. The ones\n",
    "above the diagonal have been adjusted, but we won't deal with that here.\n",
    "We do see that generosity is not significantly correlated with the other\n",
    "variables.\n",
    "\n",
    "#### Clustering\n",
    "\n",
    "We saw before we had a cluster of several overlapping variables. We can\n",
    "make some helpful visuals to view this cluster. The `heatmap()` command\n",
    "highlights highly intercorrelated variables. It also produces a\n",
    "dendrogram to show the clustering. I will do this for the full dataset,\n",
    "less the `Life.Expect2` variable (which is redundant to the\n",
    "non-transformed version). This is column 9, so I can easily drop it by\n",
    "calling `dat[,-9]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cor matrix\n",
    "cors <- cor(dat[,-9])\n",
    "\n",
    "#heatmap\n",
    "heatmap(cors, symm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-18-1.png)\n",
    "\n",
    "Here we see there is a prominent cluster of happiness, family, life\n",
    "expectancy, and GDP. These are all highly inter-correlated. You can see\n",
    "this from the bright spot in the histogram as well as from the \"long\"\n",
    "stem on the dendrogram for those variables (indicates greater\n",
    "clustering).\n",
    "\n",
    "#### A Correlation Plot\n",
    "\n",
    "Another great visual is the correlation plot. This visual helps to map\n",
    "out the sample correlations but with a greater emphasis on the\n",
    "individuals relationships (rather than clustering).\n",
    "\n",
    "There are many great tutorials for using the `corrplot` package online.\n",
    "In general, like `heatmap()`, it accepts your correlation grid as an\n",
    "input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrplot(cors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-19-1.png)\n",
    "\n",
    "By default, it replaces the numbers in the grid with shapes\n",
    "(lager/darker = stronger correlation; blue = pos, red = neg). Unlike\n",
    "`heatmap()`, it does not sort the variables into clusters for us.\n",
    "However, it has a lot of flexibility. Using `corrplot.mixed()` you can\n",
    "request numbers in one diagonal. You can also sort by the clustering\n",
    "algorithm as in `heatmap()` by adding `order=\"hclust\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrplot.mixed(cors, order=\"hclust\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-20-1.png)\n",
    "\n",
    "We can also add a grid of *p*-values with `p.mat=` and tell the function\n",
    "to \"X\" out anything not &lt; .05 by adding `sig.level = .05`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrplot.mixed(cors,\n",
    "               p.mat=corr.test(dat[,-9])$p, sig.level = .05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Mod3_Lab1_-_Correlation_files/figure-markdown_strict/unnamed-chunk-21-1.png)\n",
    "\n",
    "There you have it. There are many great ways to illustrate correlations\n",
    "among data.\n",
    "\n",
    "Conclusion\n",
    "==========\n",
    "\n",
    "Using the correlation analysis, we have both learned to find clusters of\n",
    "relationships among data and to estimate individual correlations and\n",
    "test them for significance. If we had a specific variable we wanted to\n",
    "study in greater detail, we could graduate to regression, which we will\n",
    "do in the next lab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
